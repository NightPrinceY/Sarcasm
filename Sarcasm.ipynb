{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Sarcasm",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NightPrinceY/CollegeForFun/blob/main/Sarcasm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the important liberaries for this project"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:31.078545Z",
          "iopub.execute_input": "2024-01-27T16:56:31.079489Z",
          "iopub.status.idle": "2024-01-27T16:56:31.084732Z",
          "shell.execute_reply.started": "2024-01-27T16:56:31.079438Z",
          "shell.execute_reply": "2024-01-27T16:56:31.083568Z"
        },
        "trusted": true,
        "id": "jEAirbLB_uzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import requests\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:31.086672Z",
          "iopub.execute_input": "2024-01-27T16:56:31.087121Z",
          "iopub.status.idle": "2024-01-27T16:56:31.098303Z",
          "shell.execute_reply.started": "2024-01-27T16:56:31.087088Z",
          "shell.execute_reply": "2024-01-27T16:56:31.097388Z"
        },
        "trusted": true,
        "id": "Oaj_Cask_uzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download the certain dataset for this project using url and requests library\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:31.100425Z",
          "iopub.execute_input": "2024-01-27T16:56:31.101079Z",
          "iopub.status.idle": "2024-01-27T16:56:31.110736Z",
          "shell.execute_reply.started": "2024-01-27T16:56:31.101041Z",
          "shell.execute_reply": "2024-01-27T16:56:31.109752Z"
        },
        "trusted": true,
        "id": "x21JgF4w_uzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "url = \"https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\"\n",
        "save_path = \"sarcasm.json\"\n",
        "\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "with open(save_path, \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "print(\"Dataset downloaded successfully!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:31.112368Z",
          "iopub.execute_input": "2024-01-27T16:56:31.112999Z",
          "iopub.status.idle": "2024-01-27T16:56:32.112991Z",
          "shell.execute_reply.started": "2024-01-27T16:56:31.112963Z",
          "shell.execute_reply": "2024-01-27T16:56:32.111663Z"
        },
        "trusted": true,
        "id": "Q0i3lukJ_uzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the JSON file\n",
        "with open('/kaggle/working/sarcasm.json', 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "# Initialize the lists\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "# Collect sentences and labels into the lists\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels.append(item['is_sarcastic'])\n",
        "sentences[2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:59:53.008944Z",
          "iopub.execute_input": "2024-01-27T16:59:53.009363Z",
          "iopub.status.idle": "2024-01-27T16:59:53.092065Z",
          "shell.execute_reply.started": "2024-01-27T16:59:53.009332Z",
          "shell.execute_reply": "2024-01-27T16:59:53.090862Z"
        },
        "trusted": true,
        "id": "x2cyKoNG_uzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show the dataset as dataframe wtih show the first five examples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.199933Z",
          "iopub.execute_input": "2024-01-27T16:56:32.200671Z",
          "iopub.status.idle": "2024-01-27T16:56:32.2057Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.200628Z",
          "shell.execute_reply": "2024-01-27T16:56:32.204131Z"
        },
        "trusted": true,
        "id": "dCYScVAH_uzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_json('/kaggle/working/sarcasm.json')\n",
        "dataset = pd.DataFrame(dataset)\n",
        "dataset.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.207084Z",
          "iopub.execute_input": "2024-01-27T16:56:32.207434Z",
          "iopub.status.idle": "2024-01-27T16:56:32.33626Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.207405Z",
          "shell.execute_reply": "2024-01-27T16:56:32.335033Z"
        },
        "trusted": true,
        "id": "0COpJbNS_uzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headlines=pd.DataFrame(dataset['headline'])\n",
        "headlines.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.338059Z",
          "iopub.execute_input": "2024-01-27T16:56:32.339031Z",
          "iopub.status.idle": "2024-01-27T16:56:32.35205Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.338977Z",
          "shell.execute_reply": "2024-01-27T16:56:32.350597Z"
        },
        "trusted": true,
        "id": "VABxfHnJ_uzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.DataFrame(dataset['is_sarcastic'] )\n",
        "labels.head()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.354215Z",
          "iopub.execute_input": "2024-01-27T16:56:32.354767Z",
          "iopub.status.idle": "2024-01-27T16:56:32.365511Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.354724Z",
          "shell.execute_reply": "2024-01-27T16:56:32.364409Z"
        },
        "trusted": true,
        "id": "35BVA-sB_uzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of examples to use for training\n",
        "training_size = 20000\n",
        "\n",
        "# Vocabulary size of the tokenizer\n",
        "vocab_size = 10000\n",
        "\n",
        "# Maximum length of the padded sequences\n",
        "max_length = 32\n",
        "\n",
        "# Output dimensions of the Embedding layer\n",
        "embedding_dim = 16\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.367345Z",
          "iopub.execute_input": "2024-01-27T16:56:32.368375Z",
          "iopub.status.idle": "2024-01-27T16:56:32.377671Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.368329Z",
          "shell.execute_reply": "2024-01-27T16:56:32.37661Z"
        },
        "trusted": true,
        "id": "KiZKj9fx_uzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data using slicing method\n",
        "# yahya split the as trin= 20000 and val = remains = 6709"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.383864Z",
          "iopub.execute_input": "2024-01-27T16:56:32.38429Z",
          "iopub.status.idle": "2024-01-27T16:56:32.39151Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.38426Z",
          "shell.execute_reply": "2024-01-27T16:56:32.390315Z"
        },
        "trusted": true,
        "id": "pDPnO5DV_uzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the sentences\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "# Split the labels\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.393305Z",
          "iopub.execute_input": "2024-01-27T16:56:32.393829Z",
          "iopub.status.idle": "2024-01-27T16:56:32.40527Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.393763Z",
          "shell.execute_reply": "2024-01-27T16:56:32.404352Z"
        },
        "trusted": true,
        "id": "_3Vg0Uyr_uzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for the len of test size\n",
        "len(testing_sentences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.407033Z",
          "iopub.execute_input": "2024-01-27T16:56:32.407389Z",
          "iopub.status.idle": "2024-01-27T16:56:32.421192Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.407358Z",
          "shell.execute_reply": "2024-01-27T16:56:32.420036Z"
        },
        "trusted": true,
        "id": "wWkOwhYV_uzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for padding and OOV tokens\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.422621Z",
          "iopub.execute_input": "2024-01-27T16:56:32.423518Z",
          "iopub.status.idle": "2024-01-27T16:56:32.430671Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.423485Z",
          "shell.execute_reply": "2024-01-27T16:56:32.429865Z"
        },
        "trusted": true,
        "id": "e-i0rYub_uzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creat tokenization with size words 10000 and ovv_tok as token for unkown\n",
        "tokenizer = Tokenizer(num_words= vocab_size , oov_token = oov_tok)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.432434Z",
          "iopub.execute_input": "2024-01-27T16:56:32.432836Z",
          "iopub.status.idle": "2024-01-27T16:56:32.444784Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.432784Z",
          "shell.execute_reply": "2024-01-27T16:56:32.443634Z"
        },
        "trusted": true,
        "id": "Ju6Yt1Rf_uzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runing tokenization on training data a\n",
        "# sequnce and padd as final for the traing require\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:32.446564Z",
          "iopub.execute_input": "2024-01-27T16:56:32.446962Z",
          "iopub.status.idle": "2024-01-27T16:56:33.407536Z",
          "shell.execute_reply.started": "2024-01-27T16:56:32.446927Z",
          "shell.execute_reply": "2024-01-27T16:56:33.40622Z"
        },
        "trusted": true,
        "id": "Fa8T_90__uzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the same for the test data and padd as final for val\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:33.409238Z",
          "iopub.execute_input": "2024-01-27T16:56:33.409668Z",
          "iopub.status.idle": "2024-01-27T16:56:33.578193Z",
          "shell.execute_reply.started": "2024-01-27T16:56:33.409624Z",
          "shell.execute_reply": "2024-01-27T16:56:33.576892Z"
        },
        "trusted": true,
        "id": "eTnf8Ojf_uzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels lists into numpy arrays\n",
        "training_labels = np.array(training_labels)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:33.579398Z",
          "iopub.execute_input": "2024-01-27T16:56:33.579759Z",
          "iopub.status.idle": "2024-01-27T16:56:33.585395Z",
          "shell.execute_reply.started": "2024-01-27T16:56:33.579729Z",
          "shell.execute_reply": "2024-01-27T16:56:33.584304Z"
        },
        "trusted": true,
        "id": "KSEdLwkH_uzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the coming code just for understand what happens on \"GlobalAveragePooling1D (GAP1D) layer\"\n",
        "which it take the averagepool"
      ],
      "metadata": {
        "id": "y7OqfblT_uzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize a GlobalAveragePooling1D (GAP1D) layer\n",
        "gap1d_layer = tf.keras.layers.GlobalAveragePooling1D()\n",
        "\n",
        "# Define sample array\n",
        "sample_array = np.array([[[10,2],[1,3],[1,1]]])\n",
        "\n",
        "# Print shape and contents of sample array\n",
        "print(f'shape of sample_array = {sample_array.shape}')\n",
        "print(f'sample array: {sample_array}')\n",
        "\n",
        "# Pass the sample array to the GAP1D layer\n",
        "output = gap1d_layer(sample_array)\n",
        "\n",
        "# Print shape and contents of the GAP1D output array\n",
        "print(f'output shape of gap1d_layer: {output.shape}')\n",
        "print(f'output array of gap1d_layer: {output.numpy()}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:33.58668Z",
          "iopub.execute_input": "2024-01-27T16:56:33.587027Z",
          "iopub.status.idle": "2024-01-27T16:56:33.721422Z",
          "shell.execute_reply.started": "2024-01-27T16:56:33.586998Z",
          "shell.execute_reply": "2024-01-27T16:56:33.719931Z"
        },
        "trusted": true,
        "id": "wxF3Vu2p_uzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:33.722939Z",
          "iopub.execute_input": "2024-01-27T16:56:33.723402Z",
          "iopub.status.idle": "2024-01-27T16:56:33.841839Z",
          "shell.execute_reply.started": "2024-01-27T16:56:33.72336Z",
          "shell.execute_reply": "2024-01-27T16:56:33.840902Z"
        },
        "trusted": true,
        "id": "ahNH_LbH_uzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:33.843189Z",
          "iopub.execute_input": "2024-01-27T16:56:33.843892Z",
          "iopub.status.idle": "2024-01-27T16:56:33.874876Z",
          "shell.execute_reply.started": "2024-01-27T16:56:33.843849Z",
          "shell.execute_reply": "2024-01-27T16:56:33.873878Z"
        },
        "trusted": true,
        "id": "ufk8ZqCR_uzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:33.876158Z",
          "iopub.execute_input": "2024-01-27T16:56:33.876612Z",
          "iopub.status.idle": "2024-01-27T16:56:33.911134Z",
          "shell.execute_reply.started": "2024-01-27T16:56:33.876566Z",
          "shell.execute_reply": "2024-01-27T16:56:33.909934Z"
        },
        "trusted": true,
        "id": "jKbDZIEu_uzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(training_padded, training_labels,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data=(testing_padded, testing_labels),\n",
        "                    verbose=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:56:33.912988Z",
          "iopub.execute_input": "2024-01-27T16:56:33.919395Z",
          "iopub.status.idle": "2024-01-27T16:57:56.8603Z",
          "shell.execute_reply.started": "2024-01-27T16:56:33.91934Z",
          "shell.execute_reply": "2024-01-27T16:57:56.858799Z"
        },
        "trusted": true,
        "id": "IZZMHCgQ_uzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:57:56.862297Z",
          "iopub.execute_input": "2024-01-27T16:57:56.862707Z",
          "iopub.status.idle": "2024-01-27T16:57:56.86939Z",
          "shell.execute_reply.started": "2024-01-27T16:57:56.862672Z",
          "shell.execute_reply": "2024-01-27T16:57:56.868093Z"
        },
        "trusted": true,
        "id": "Shsgbj11_uzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy and loss\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:57:56.870761Z",
          "iopub.execute_input": "2024-01-27T16:57:56.871143Z",
          "iopub.status.idle": "2024-01-27T16:57:57.504217Z",
          "shell.execute_reply.started": "2024-01-27T16:57:56.871113Z",
          "shell.execute_reply": "2024-01-27T16:57:57.502968Z"
        },
        "trusted": true,
        "id": "Fq3Gx03x_uzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index-word dictionary\n",
        "reverse_word_index = tokenizer.index_word\n",
        "\n",
        "# Get the embedding layer from the model (i.e. first layer)\n",
        "embedding_layer = model.layers[0]\n",
        "\n",
        "# Get the weights of the embedding layer\n",
        "embedding_weights = embedding_layer.get_weights()[0]\n",
        "\n",
        "# Print the shape. Expected is (vocab_size, embedding_dim)\n",
        "print(embedding_weights.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:57:57.508398Z",
          "iopub.execute_input": "2024-01-27T16:57:57.508754Z",
          "iopub.status.idle": "2024-01-27T16:57:57.51838Z",
          "shell.execute_reply.started": "2024-01-27T16:57:57.508724Z",
          "shell.execute_reply": "2024-01-27T16:57:57.517118Z"
        },
        "trusted": true,
        "id": "r7eOblgU_uzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i hope you enjoyed ..you can test the model with your words⬇️⬇️"
      ],
      "metadata": {
        "id": "moHzTfBU_uzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new = input(\"new_sentence: \")\n",
        "new_review = [new]\n",
        "\n",
        "# Tokenize and pad the new review\n",
        "new_sequences = tokenizer.texts_to_sequences(new_review)\n",
        "new_padded = pad_sequences(new_sequences, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "# Make a prediction using the trained model\n",
        "prediction = model.predict(new_padded)\n",
        "if prediction[0] > 0.5 :\n",
        "    print('\\n positive ')\n",
        "else:\n",
        "     print('\\n negative ')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T16:59:59.484231Z",
          "iopub.execute_input": "2024-01-27T16:59:59.484779Z",
          "iopub.status.idle": "2024-01-27T17:00:02.85642Z",
          "shell.execute_reply.started": "2024-01-27T16:59:59.484733Z",
          "shell.execute_reply": "2024-01-27T17:00:02.855016Z"
        },
        "trusted": true,
        "id": "sFUSPZeo_uzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7hb9MEQb_uzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}